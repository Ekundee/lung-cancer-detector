{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import cv2\n",
    "import numpy as np\n",
    "# import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_directory = r\"C:/Users/user/Documents/Machine learning/Datasets/chest_ct_scan/Data/train\"\n",
    "# test_data_directory = r\"C:/Users/user/Documents/Machine learning/Datasets/chest_ct_scan/Data/test\"\n",
    "\n",
    "# train_data_directory = r\"C:/Users/user/Documents/Machine learning/Datasets/Combined_lung_cancer/train\"\n",
    "# test_data_directory = r\"C:/Users/user/Documents/Machine learning/Datasets/Combined_lung_cancer/test\"\n",
    "\n",
    "train_data_directory = r\"C:/Users/user/Documents/Machine learning/Datasets/Combined_lung_cancer 2/train\"\n",
    "test_data_directory = r\"C:/Users/user/Documents/Machine learning/Datasets/Combined_lung_cancer 2/test\"\n",
    "valid_data_directory = r\"C:/Users/user/Documents/Machine learning/Datasets/chest_ct_scan/Data/valid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1663 files belonging to 2 classes.\n",
      "Found 278 files belonging to 2 classes.\n",
      "Found 63 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_data_directory,\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=32,\n",
    "    image_size=(28,28),\n",
    "    labels=\"inferred\"\n",
    ")\n",
    "\n",
    "test_data = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_data_directory,\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=32,\n",
    "    image_size=(28,28),\n",
    "    labels=\"inferred\"\n",
    ")\n",
    "\n",
    "valid_data = tf.keras.utils.image_dataset_from_directory(\n",
    "    valid_data_directory,\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=32,\n",
    "    image_size=(28,28),\n",
    "    labels=\"inferred\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002493E65FDC0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_train_function.<locals>.train_function at 0x000002493E65FDC0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002493E65FDC0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_train_function.<locals>.train_function at 0x000002493E65FDC0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002493E65FDC0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_train_function.<locals>.train_function at 0x000002493E65FDC0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "49/49 [==============================] - 90s 2s/step - loss: 1.4631 - accuracy: 0.5729\n",
      "Epoch 2/20\n",
      "49/49 [==============================] - 78s 2s/step - loss: 0.3926 - accuracy: 0.8354\n",
      "Epoch 3/20\n",
      "49/49 [==============================] - 69s 1s/step - loss: 0.1703 - accuracy: 0.9430\n",
      "Epoch 4/20\n",
      "49/49 [==============================] - 60s 1s/step - loss: 0.1025 - accuracy: 0.9605\n",
      "Epoch 5/20\n",
      "49/49 [==============================] - 27s 509ms/step - loss: 0.0329 - accuracy: 0.9896\n",
      "Epoch 6/20\n",
      "49/49 [==============================] - 64s 1s/step - loss: 0.0060 - accuracy: 0.9994\n",
      "Epoch 7/20\n",
      "49/49 [==============================] - 64s 1s/step - loss: 0.0130 - accuracy: 0.9942\n",
      "Epoch 8/20\n",
      "49/49 [==============================] - 70s 1s/step - loss: 0.1031 - accuracy: 0.9657\n",
      "Epoch 9/20\n",
      "49/49 [==============================] - 64s 1s/step - loss: 0.0616 - accuracy: 0.9767\n",
      "Epoch 10/20\n",
      "49/49 [==============================] - 65s 1s/step - loss: 0.0191 - accuracy: 0.9929\n",
      "Epoch 11/20\n",
      "49/49 [==============================] - 63s 1s/step - loss: 0.0074 - accuracy: 0.9987\n",
      "Epoch 12/20\n",
      "49/49 [==============================] - 69s 1s/step - loss: 0.0077 - accuracy: 0.9968\n",
      "Epoch 13/20\n",
      "49/49 [==============================] - 63s 1s/step - loss: 0.0103 - accuracy: 0.9961\n",
      "Epoch 14/20\n",
      "49/49 [==============================] - 63s 1s/step - loss: 0.0045 - accuracy: 0.9981\n",
      "Epoch 15/20\n",
      "49/49 [==============================] - 73s 1s/step - loss: 0.0122 - accuracy: 0.9955\n",
      "Epoch 16/20\n",
      "49/49 [==============================] - 77s 2s/step - loss: 0.0416 - accuracy: 0.9870\n",
      "Epoch 17/20\n",
      "49/49 [==============================] - 65s 1s/step - loss: 0.0196 - accuracy: 0.9929\n",
      "Epoch 18/20\n",
      "49/49 [==============================] - 55s 1s/step - loss: 0.0388 - accuracy: 0.9851\n",
      "Epoch 19/20\n",
      "49/49 [==============================] - 56s 1s/step - loss: 0.0464 - accuracy: 0.9870\n",
      "Epoch 20/20\n",
      "49/49 [==============================] - 60s 1s/step - loss: 0.0482 - accuracy: 0.9831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24943547610>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# THE MODEL\n",
    "model = tf.keras.Sequential([\n",
    "    # FIRST COVULUTIONAL LAYER\n",
    "    tf.keras.layers.Conv2D(32, 3, input_shape=(28,28,1), activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "\n",
    "    # # SECOND COVULUTIONAL LAYER\n",
    "    tf.keras.layers.Conv2D(64, 3, activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "\n",
    "     # # THIRD COVULUTIONAL LAYER\n",
    "    tf.keras.layers.Conv2D(128, 3, activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "\n",
    "\n",
    "    # FLAATEN LAYER FOR THE ANN\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    # HIDDEN LAYERS\n",
    "    # tf.keras.layers.Dense(2048, activation=tf.nn.relu),\n",
    "    # tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "#     tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "\n",
    "    # OUTPUTR LAYER\n",
    "    tf.keras.layers.Dense(4, activation=tf.nn.softmax)\n",
    "\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.optimizers.Adam(), loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, batch_size=32, epochs=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024941053040> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_train_function.<locals>.train_function at 0x0000024941053040>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024941053040> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_train_function.<locals>.train_function at 0x0000024941053040>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024941053040> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_train_function.<locals>.train_function at 0x0000024941053040>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "49/49 [==============================] - 16s 289ms/step - loss: 1.0906 - accuracy: 0.6150\n",
      "Epoch 2/20\n",
      "49/49 [==============================] - 12s 232ms/step - loss: 0.4603 - accuracy: 0.7894\n",
      "Epoch 3/20\n",
      "49/49 [==============================] - 7s 132ms/step - loss: 0.3546 - accuracy: 0.8458\n",
      "Epoch 4/20\n",
      "49/49 [==============================] - 7s 136ms/step - loss: 0.1515 - accuracy: 0.9410\n",
      "Epoch 5/20\n",
      "49/49 [==============================] - 6s 123ms/step - loss: 0.0861 - accuracy: 0.9702\n",
      "Epoch 6/20\n",
      "49/49 [==============================] - 8s 149ms/step - loss: 0.0445 - accuracy: 0.9851\n",
      "Epoch 7/20\n",
      "49/49 [==============================] - 7s 139ms/step - loss: 0.0649 - accuracy: 0.9793\n",
      "Epoch 8/20\n",
      "49/49 [==============================] - 6s 107ms/step - loss: 0.0795 - accuracy: 0.9708\n",
      "Epoch 9/20\n",
      "49/49 [==============================] - 6s 106ms/step - loss: 0.0318 - accuracy: 0.9903\n",
      "Epoch 10/20\n",
      "49/49 [==============================] - 8s 152ms/step - loss: 0.0039 - accuracy: 0.9987\n",
      "Epoch 11/20\n",
      "49/49 [==============================] - 13s 251ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "49/49 [==============================] - 14s 267ms/step - loss: 2.3293e-04 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "49/49 [==============================] - 14s 278ms/step - loss: 1.1426e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "49/49 [==============================] - 11s 221ms/step - loss: 7.0142e-05 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "49/49 [==============================] - 12s 235ms/step - loss: 4.9727e-05 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "49/49 [==============================] - 14s 280ms/step - loss: 3.7875e-05 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "49/49 [==============================] - 13s 266ms/step - loss: 3.0435e-05 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "49/49 [==============================] - 16s 316ms/step - loss: 2.4826e-05 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "49/49 [==============================] - 14s 261ms/step - loss: 2.0826e-05 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "49/49 [==============================] - 22s 432ms/step - loss: 1.7739e-05 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2494103b3d0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# THE MODEL\n",
    "model = tf.keras.Sequential([\n",
    "    # FIRST COVULUTIONAL LAYER\n",
    "    tf.keras.layers.Conv2D(32, 3, input_shape=(28,28,1), activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "\n",
    "    # # SECOND COVULUTIONAL LAYER\n",
    "    tf.keras.layers.Conv2D(64, 3, activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "\n",
    "     # # THIRD COVULUTIONAL LAYER\n",
    "    tf.keras.layers.Conv2D(128, 3, activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "\n",
    "\n",
    "    # FLAATEN LAYER FOR THE ANN\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    # HIDDEN LAYERS\n",
    "    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "\n",
    "    # OUTPUTR LAYER\n",
    "    tf.keras.layers.Dense(2, activation=tf.nn.softmax)\n",
    "\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.optimizers.Adam(), loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, batch_size=32, epochs=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002494803F160> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_train_function.<locals>.train_function at 0x000002494803F160>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002494803F160> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_train_function.<locals>.train_function at 0x000002494803F160>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002494803F160> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_train_function.<locals>.train_function at 0x000002494803F160>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "52/52 [==============================] - 20s 310ms/step - loss: 0.9151 - accuracy: 0.6446\n",
      "Epoch 2/20\n",
      "52/52 [==============================] - 13s 248ms/step - loss: 0.3687 - accuracy: 0.8515\n",
      "Epoch 3/20\n",
      "52/52 [==============================] - 9s 175ms/step - loss: 0.2346 - accuracy: 0.8966\n",
      "Epoch 4/20\n",
      "52/52 [==============================] - 7s 125ms/step - loss: 0.0790 - accuracy: 0.9741\n",
      "Epoch 5/20\n",
      "52/52 [==============================] - 8s 138ms/step - loss: 0.0428 - accuracy: 0.9844\n",
      "Epoch 6/20\n",
      "52/52 [==============================] - 14s 274ms/step - loss: 0.0276 - accuracy: 0.9910\n",
      "Epoch 7/20\n",
      "52/52 [==============================] - 26s 486ms/step - loss: 0.0336 - accuracy: 0.9886\n",
      "Epoch 8/20\n",
      "52/52 [==============================] - 18s 340ms/step - loss: 0.0307 - accuracy: 0.9886\n",
      "Epoch 9/20\n",
      "52/52 [==============================] - 15s 274ms/step - loss: 0.0409 - accuracy: 0.9856\n",
      "Epoch 10/20\n",
      "52/52 [==============================] - 14s 256ms/step - loss: 0.0462 - accuracy: 0.9892\n",
      "Epoch 11/20\n",
      "52/52 [==============================] - 12s 227ms/step - loss: 0.0046 - accuracy: 0.9994\n",
      "Epoch 12/20\n",
      "52/52 [==============================] - 14s 263ms/step - loss: 3.6946e-04 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "52/52 [==============================] - 10s 194ms/step - loss: 1.3001e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "52/52 [==============================] - 14s 262ms/step - loss: 6.6105e-05 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "52/52 [==============================] - 24s 451ms/step - loss: 3.3757e-05 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "52/52 [==============================] - 23s 444ms/step - loss: 1.6996e-05 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "52/52 [==============================] - 42s 785ms/step - loss: 9.8326e-06 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "52/52 [==============================] - 38s 699ms/step - loss: 6.8228e-06 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "52/52 [==============================] - 55s 999ms/step - loss: 5.3420e-06 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "52/52 [==============================] - 18s 339ms/step - loss: 4.2797e-06 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2494b68fb50>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# THE MODEL\n",
    "model = tf.keras.Sequential([\n",
    "    # FIRST COVULUTIONAL LAYER\n",
    "    tf.keras.layers.Conv2D(32, 3, input_shape=(28,28,1), activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "\n",
    "    # # SECOND COVULUTIONAL LAYER\n",
    "    tf.keras.layers.Conv2D(64, 3, activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "\n",
    "     # # THIRD COVULUTIONAL LAYER\n",
    "    tf.keras.layers.Conv2D(128, 3, activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "\n",
    "\n",
    "    # FLAATEN LAYER FOR THE ANN\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    # HIDDEN LAYERS\n",
    "    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "\n",
    "    # OUTPUTR LAYER\n",
    "    tf.keras.layers.Dense(2, activation=tf.nn.softmax)\n",
    "\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.optimizers.Adam(), loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, batch_size=32, epochs=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 17ms/step - loss: 0.2312 - accuracy: 0.9365\n",
      "[0.2311723828315735, 0.9365079402923584]\n"
     ]
    }
   ],
   "source": [
    "# predictions = model.predict(test_data)\n",
    "evaluation = model.evaluate(valid_data)\n",
    "\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x000002494803F700> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function trace_model_call.<locals>._wrapped_model at 0x000002494803F700>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x000002494803F700> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function trace_model_call.<locals>._wrapped_model at 0x000002494803F700>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x000002494803F700> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function trace_model_call.<locals>._wrapped_model at 0x000002494803F700>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000249481E5D30> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000249481E5D30>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000249481E5D30> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000249481E5D30>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000249481E5D30> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000249481E5D30>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_lung_cancer_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_lung_cancer_model\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.autograph.experimental.do_not_convert\n",
    "model.save(\"best_lung_cancer_model.h5\")\n",
    "model.save(\"best_lung_cancer_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected input shape: (None, 28, 28, 1)\n",
      "(481, 617, 4)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) c:\\b\\abs_f8n1j3l9l0\\croot\\opencv-suite_1691622637237\\work\\modules\\imgproc\\src\\color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function '__cdecl cv::impl::`anonymous-namespace'::CvtHelper<struct cv::impl::`anonymous namespace'::Set<3,4,-1>,struct cv::impl::A0x4d30d89e::Set<1,-1,-1>,struct cv::impl::A0x4d30d89e::Set<0,2,5>,2>::CvtHelper(const class cv::_InputArray &,const class cv::_OutputArray &,int)'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Documents\\GitHub\\lung cancer detector\\MachineLearning\\main2.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/GitHub/lung%20cancer%20detector/MachineLearning/main2.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m resized_image \u001b[39m=\u001b[39m image[:, :, :\u001b[39m1\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/GitHub/lung%20cancer%20detector/MachineLearning/main2.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m grayscale_image \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexpand_dims(grayscale_image, axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/GitHub/lung%20cancer%20detector/MachineLearning/main2.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m grayscale_image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcvtColor(grayscale_image, cv2\u001b[39m.\u001b[39;49mCOLOR_BGR2GRAY)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/GitHub/lung%20cancer%20detector/MachineLearning/main2.ipynb#X13sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m resized_image \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mresize(grayscale_image, size\u001b[39m=\u001b[39m(\u001b[39m28\u001b[39m, \u001b[39m28\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/GitHub/lung%20cancer%20detector/MachineLearning/main2.ipynb#X13sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mprint\u001b[39m(resized_image\u001b[39m.\u001b[39mshape)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) c:\\b\\abs_f8n1j3l9l0\\croot\\opencv-suite_1691622637237\\work\\modules\\imgproc\\src\\color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function '__cdecl cv::impl::`anonymous-namespace'::CvtHelper<struct cv::impl::`anonymous namespace'::Set<3,4,-1>,struct cv::impl::A0x4d30d89e::Set<1,-1,-1>,struct cv::impl::A0x4d30d89e::Set<0,2,5>,2>::CvtHelper(const class cv::_InputArray &,const class cv::_OutputArray &,int)'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 1\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"best_lung_cancer_model.h5\")\n",
    "input_shape = model.layers[0].input_shape\n",
    "print(\"Expected input shape:\", input_shape)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the file path of the image you want to load\n",
    "image_path = 'C:/Users/user/Documents/Machine learning/Datasets/chest_ct_scan/Data/valid/normal/4(2).png'  # Replace with the actual file path\n",
    "\n",
    "\n",
    "# Load the image using TensorFlow\n",
    "image = tf.io.read_file(image_path)\n",
    "image = tf.image.decode_image(image)\n",
    "print(image.shape)\n",
    "grayscale_image = np.mean(image[:, :, :3], axis=2)\n",
    "grayscale_image = np.expand_dims(grayscale_image, axis=2)\n",
    "resized_image = tf.image.resize(grayscale_image, size=(28, 28))\n",
    "print(resized_image.shape)\n",
    "img = np.array([resized_image])\n",
    "print(img.shape)\n",
    "\n",
    "\n",
    "# resized_image = image[:, :, :1]\n",
    "# print(resized_image.shape)\n",
    "\n",
    "# resized_image = tf.image.resize(image, size=(28, 28,1))\n",
    "# resized_image = tf.expand_dims(resized_image, axis=0)  # Adds a batch dimension with size 1\n",
    "\n",
    "# resized_image = tf.ensure_shape(resized_image, (None, 28, 28, 1))\n",
    "# print(resized_image.shape)\n",
    "\n",
    "# your_image = cv2.imread(image_path) \n",
    "# # Load and resize your image to (28, 28)\n",
    "# input_image = cv2.resize(your_image, (28, 28))\n",
    "\n",
    "# # Handle the 4 channels (e.g., take the average)\n",
    "# input_image = np.mean(input_image, axis=2)\n",
    "\n",
    "# # Normalize the image if your model expects normalized inputs\n",
    "# input_image = input_image / 255.0  # You can adjust this if your model uses different scaling\n",
    "\n",
    "# # Add a batch dimension to match the model's input shape\n",
    "# input_image = np.expand_dims(input_image, axis=0)\n",
    "\n",
    "# print(input_image.shape)\n",
    "# Display the image using Matplotlib\n",
    "# plt.imshow(input_image)\n",
    "plt.imshow(resized_image)\n",
    "plt.axis('off')  # Optional: Turn off axis labels\n",
    "plt.show()\n",
    "\n",
    "# # resized_data = tf.image.resize(input_image, size=(28, 28))\n",
    "pred = model.predict(img)\n",
    "\n",
    "print(pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.2542449235916138, 0.6571428775787354]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[8.556180000305176, 0.39047619700431824]\n",
    "[2.9407191276550293, 0.5492063760757446]\n",
    "[1.2542449235916138, 0.6571428775787354]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU_support_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
